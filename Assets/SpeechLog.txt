I am preparing for a presentation, and my transcription is below. Can you list three questions for my content(display only the questions) and three suggestions for me to make the content more clear? Answer in bullet points and in plain text (no markdown or code).

Full transcription:
We present DeckTalk, a VR app that enables users to practice giving talks in virtualized environments to an AI-powered audience that asks unique, targeted questions. In addition to a realistic presentation experience, DeckTalk will also generate a graded evaluation based on verbal and non-verbal information to help users hone their presentation skills.

Presentation is common in both academic and professional settings. To refine the presentation, people often film themselves giving talks in front of a mirror, where a limited amount of feedback can be obtained. How can we make practice talks more effective and closer to real life? With DeckTalk, anyone can practice giving talks in various virtualized environments (e.g., auditorium, classroom) to an AI-powered audience of any size that asks unique, targeted questions to the presentation. In addition to simulated real-life question-answering,  DeckTalk also grades the user’s performance on verbal and non-verbal information, such as content complexity, movements, and timings, and generates summarized feedback on how users can improve their presentations. These metrics can also be stored across sessions to let users see their improvements. Users have the option to upload their own slide decks for analysis alongside their presentations. Alternatively, they can practice with an AI-generated, improvised presentation. This method helps enhance general presentation skills and the ability to respond to unexpected situations.

VirtualSpeech has developed a similar application with VR and AI, including varied workplace settings, virtual interactable avatars, and AI-generated gradings. It can also be accessed through a web browser without a VR headset. However, VirtualSpeech requires the conversion of presentation slides into PDFs, and it costs $400 a year. In contrast, we allow users to bring the presentation into the virtual environment through a web browser (VirtualSpeech uses an external website to upload a PDF) and are planning to offer the app for free by open-sourcing the code. In addition, our app enables users to improve their general presentation skills by practicing against AI-generated presentation slides.

Users initiate their virtual presentation by navigating to the slides via an embedded web browser. They then choose the style of their talk, such as a TED Talk/conference style, a colloquium with Q&A, or a sales pitch. This choice places them in a suitable virtual reality (VR) environment—perhaps on an elevated VR stage or behind a VR podium, complete with an audience tailored to the type of talk they are giving. Their presentation is displayed on a large screen behind them, and a smaller screen in front of them shows their slide deck, which they can control.

To start their presentation, users press a 'start' button and begin speaking to the virtual audience. They can stick to a predetermined script or discuss the topics shown on the current slide. Slides are navigable via a controller or hand gestures. Depending on the presentation format, the VR audience may raise their hands to ask questions or interrupt the presentation. Users can opt for a presentation with set time limits, focused on engaging the audience throughout, or one that allows for interactive audience participation with questions.

After the presentation, there may be a Q&A session for a specific duration. Users conclude their session by pressing 'end,' after which they receive feedback on various aspects such as timing, speech clarity, use of filler words, and non-verbal communication effectiveness. Following the session, users can choose to retry the presentation, switch venues, or select a different talk type. They also have the option to save their profile to track their progress over time.
